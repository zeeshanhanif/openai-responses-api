{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3aa0d0-ff83-4f55-81a8-11aed0ebf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import rich\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794d7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4deb00",
   "metadata": {},
   "source": [
    "## File Search is only part of Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed959b",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/tools-file-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfeef36",
   "metadata": {},
   "source": [
    "File Search works with a vector store, which we will need to create within OpenAI. The entire process, including storing the file, generating embeddings, and searching within the vector store, will be managed by OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05602b",
   "metadata": {},
   "source": [
    "The `create_file` function uploads a file to the OpenAI API and supports both remote and local files.\n",
    "If the file path is a URL, it downloads the file content, stores it in memory and then upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed86d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to Upload a file\n",
    "def create_file(openai, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = openai.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = openai.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4a95d",
   "metadata": {},
   "source": [
    "##### Call function to upload a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-4GoREtVZ14bPdCKHXsva8k\n"
     ]
    }
   ],
   "source": [
    "file_id = create_file(openai, \"https://cdn.openai.com/API/docs/deep_research_blog.pdf\")\n",
    "# file_id = create_file(openai, \"docs/Panaversity-Certified-Agentic-and-Robotic-AI-Engineer.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e353f2",
   "metadata": {},
   "source": [
    "### Create a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d53e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_67e389ea42008191964bfc8f0d0e76ea\n"
     ]
    }
   ],
   "source": [
    "vector_store = openai.vector_stores.create(\n",
    "    name=\"knowledge_base_2\"\n",
    ")\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f381f",
   "metadata": {},
   "source": [
    "### Add a file to a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4dbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VectorStoreFile</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742965256</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">last_error</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vector_store.file'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'in_progress'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_bytes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">vector_store_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vs_67e389ea42008191964bfc8f0d0e76ea'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">attributes</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunking_strategy</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StaticFileChunkingStrategyObject</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">static</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StaticFileChunkingStrategy</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">chunk_overlap_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_chunk_size_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'static'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mVectorStoreFile\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1742965256\u001b[0m,\n",
       "    \u001b[33mlast_error\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'vector_store.file'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'in_progress'\u001b[0m,\n",
       "    \u001b[33musage_bytes\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "    \u001b[33mvector_store_id\u001b[0m=\u001b[32m'vs_67e389ea42008191964bfc8f0d0e76ea'\u001b[0m,\n",
       "    \u001b[33mattributes\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mchunking_strategy\u001b[0m=\u001b[1;35mStaticFileChunkingStrategyObject\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mstatic\u001b[0m=\u001b[1;35mStaticFileChunkingStrategy\u001b[0m\u001b[1m(\u001b[0m\u001b[33mchunk_overlap_tokens\u001b[0m=\u001b[1;36m400\u001b[0m, \u001b[33mmax_chunk_size_tokens\u001b[0m=\u001b[1;36m800\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'static'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = openai.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")\n",
    "rich.print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675926e8",
   "metadata": {},
   "source": [
    "### Check the status of files in vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96766b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SyncCursorPage<span style=\"font-weight: bold\">[</span>VectorStoreFile<span style=\"font-weight: bold\">](</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VectorStoreFile</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742965256</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">last_error</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vector_store.file'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">usage_bytes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66539</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">vector_store_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vs_67e389ea42008191964bfc8f0d0e76ea'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">attributes</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">chunking_strategy</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StaticFileChunkingStrategyObject</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">static</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StaticFileChunkingStrategy</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">chunk_overlap_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_chunk_size_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'static'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">has_more</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'list'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">first_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">last_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "SyncCursorPage\u001b[1m[\u001b[0mVectorStoreFile\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdata\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mVectorStoreFile\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "            \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1742965256\u001b[0m,\n",
       "            \u001b[33mlast_error\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mobject\u001b[0m=\u001b[32m'vector_store.file'\u001b[0m,\n",
       "            \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "            \u001b[33musage_bytes\u001b[0m=\u001b[1;36m66539\u001b[0m,\n",
       "            \u001b[33mvector_store_id\u001b[0m=\u001b[32m'vs_67e389ea42008191964bfc8f0d0e76ea'\u001b[0m,\n",
       "            \u001b[33mattributes\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mchunking_strategy\u001b[0m=\u001b[1;35mStaticFileChunkingStrategyObject\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mstatic\u001b[0m=\u001b[1;35mStaticFileChunkingStrategy\u001b[0m\u001b[1m(\u001b[0m\u001b[33mchunk_overlap_tokens\u001b[0m=\u001b[1;36m400\u001b[0m, \u001b[33mmax_chunk_size_tokens\u001b[0m=\u001b[1;36m800\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mtype\u001b[0m=\u001b[32m'static'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mhas_more\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'list'\u001b[0m,\n",
       "    \u001b[33mfirst_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "    \u001b[33mlast_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = openai.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "rich.print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3106bb70",
   "metadata": {},
   "source": [
    "Now in Responses API call, we can provide `file_search` tool and `vector_store_ids`.\n",
    "\n",
    "Annotation object in response will provide information about file\n",
    "```\n",
    "AnnotationFileCitation(\n",
    "    file_id='file-4GoREtVZ14bPdCKHXsva8k',\n",
    "    index=1939,\n",
    "    type='file_citation',\n",
    "    filename='deep_research_blog.pdf'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff8ab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Deep Research by OpenAI is a new capability that enables users to conduct extensive and complex research tasks \n",
       "quickly and efficiently. Some key features include:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Multi-Step Research**: Deep Research allows users to generate outputs through a series of reasoning and data \n",
       "synthesis from numerous online sources. It can handle intricate queries that would typically require significant \n",
       "human effort.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Independence and Automation**: Users provide a prompt, and the system independently finds, analyzes, and \n",
       "synthesizes the required information, generating comprehensive reports similar to what a research analyst might \n",
       "produce.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Web Browsing and Data Analysis**: It utilizes a specialized version of OpenAI's model optimized for web \n",
       "browsing and data analysis, making it capable of interpreting vast amounts of information, including text, images, \n",
       "and PDFs.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Documentation and Citations**: Every result is accompanied by detailed documentation and citations, ensuring \n",
       "that users can verify the information and understand the reasoning behind the outputs.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Targeted Use Cases**: Deep Research is particularly beneficial for professionals in finance, science, policy, \n",
       "and engineering, as well as consumers seeking personalized recommendations that require extensive research.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. **Performance**: Initial evaluations show that the model powering Deep Research significantly outperforms \n",
       "previous models in expert-level tasks and public evaluations, achieving higher accuracy.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. **Accessibility and Future Plans**: Currently, Deep Research is available to Pro users, with plans to extend \n",
       "access to more user tiers over time, and enhancements will be rolled out to improve the system based on user \n",
       "feedback and usage data.\n",
       "\n",
       "This represents a notable advancement towards OpenAI's broader goal of achieving artificial general intelligence \n",
       "<span style=\"font-weight: bold\">(</span>AGI<span style=\"font-weight: bold\">)</span>, specifically in the realm of knowledge synthesis and research capabilities.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Deep Research by OpenAI is a new capability that enables users to conduct extensive and complex research tasks \n",
       "quickly and efficiently. Some key features include:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Multi-Step Research**: Deep Research allows users to generate outputs through a series of reasoning and data \n",
       "synthesis from numerous online sources. It can handle intricate queries that would typically require significant \n",
       "human effort.\n",
       "\n",
       "\u001b[1;36m2\u001b[0m. **Independence and Automation**: Users provide a prompt, and the system independently finds, analyzes, and \n",
       "synthesizes the required information, generating comprehensive reports similar to what a research analyst might \n",
       "produce.\n",
       "\n",
       "\u001b[1;36m3\u001b[0m. **Web Browsing and Data Analysis**: It utilizes a specialized version of OpenAI's model optimized for web \n",
       "browsing and data analysis, making it capable of interpreting vast amounts of information, including text, images, \n",
       "and PDFs.\n",
       "\n",
       "\u001b[1;36m4\u001b[0m. **Documentation and Citations**: Every result is accompanied by detailed documentation and citations, ensuring \n",
       "that users can verify the information and understand the reasoning behind the outputs.\n",
       "\n",
       "\u001b[1;36m5\u001b[0m. **Targeted Use Cases**: Deep Research is particularly beneficial for professionals in finance, science, policy, \n",
       "and engineering, as well as consumers seeking personalized recommendations that require extensive research.\n",
       "\n",
       "\u001b[1;36m6\u001b[0m. **Performance**: Initial evaluations show that the model powering Deep Research significantly outperforms \n",
       "previous models in expert-level tasks and public evaluations, achieving higher accuracy.\n",
       "\n",
       "\u001b[1;36m7\u001b[0m. **Accessibility and Future Plans**: Currently, Deep Research is available to Pro users, with plans to extend \n",
       "access to more user tiers over time, and enhancements will be rolled out to improve the system based on user \n",
       "feedback and usage data.\n",
       "\n",
       "This represents a notable advancement towards OpenAI's broader goal of achieving artificial general intelligence \n",
       "\u001b[1m(\u001b[0mAGI\u001b[1m)\u001b[0m, specifically in the realm of knowledge synthesis and research capabilities.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseFileSearchToolCall</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fs_67e38ae6c04c81928847954bfb6a3d750b92b94f1d963d71'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">queries</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'What is deep research by OpenAI?'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_search_call'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">results</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'msg_67e38ae9909c8192b29105f1b9a8cadb0b92b94f1d963d71'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputText</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1495</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>,\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1495</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>,\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1495</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>,\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1495</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>,\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>,\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1939</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Deep Research by OpenAI is a new capability that enables users to conduct extensive and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex research tasks quickly and efficiently. Some key features include:\\n\\n1. **Multi-Step Research**: Deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Research allows users to generate outputs through a series of reasoning and data synthesis from numerous online </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sources. It can handle intricate queries that would typically require significant human effort.\\n\\n2. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Independence and Automation**: Users provide a prompt, and the system independently finds, analyzes, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthesizes the required information, generating comprehensive reports similar to what a research analyst might </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">produce.\\n\\n3. **Web Browsing and Data Analysis**: It utilizes a specialized version of OpenAI's model optimized </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for web browsing and data analysis, making it capable of interpreting vast amounts of information, including text, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">images, and PDFs.\\n\\n4. **Documentation and Citations**: Every result is accompanied by detailed documentation and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">citations, ensuring that users can verify the information and understand the reasoning behind the outputs.\\n\\n5. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Targeted Use Cases**: Deep Research is particularly beneficial for professionals in finance, science, policy, and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engineering, as well as consumers seeking personalized recommendations that require extensive research.\\n\\n6. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Performance**: Initial evaluations show that the model powering Deep Research significantly outperforms previous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models in expert-level tasks and public evaluations, achieving higher accuracy.\\n\\n7. **Accessibility and Future </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Plans**: Currently, Deep Research is available to Pro users, with plans to extend access to more user tiers over </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">time, and enhancements will be rolled out to improve the system based on user feedback and usage data.\\n\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">represents a notable advancement towards OpenAI's broader goal of achieving artificial general intelligence (AGI), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specifically in the realm of knowledge synthesis and research capabilities.\"</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'output_text'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mResponseFileSearchToolCall\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'fs_67e38ae6c04c81928847954bfb6a3d750b92b94f1d963d71'\u001b[0m,\n",
       "        \u001b[33mqueries\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'What is deep research by OpenAI?'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'file_search_call'\u001b[0m,\n",
       "        \u001b[33mresults\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mResponseOutputMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'msg_67e38ae9909c8192b29105f1b9a8cadb0b92b94f1d963d71'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mResponseOutputText\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                        \u001b[33mindex\u001b[0m=\u001b[1;36m1495\u001b[0m,\n",
       "                        \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m,\n",
       "                    \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                        \u001b[33mindex\u001b[0m=\u001b[1;36m1495\u001b[0m,\n",
       "                        \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m,\n",
       "                    \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                        \u001b[33mindex\u001b[0m=\u001b[1;36m1495\u001b[0m,\n",
       "                        \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m,\n",
       "                    \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                        \u001b[33mindex\u001b[0m=\u001b[1;36m1495\u001b[0m,\n",
       "                        \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m,\n",
       "                    \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                        \u001b[33mindex\u001b[0m=\u001b[1;36m1742\u001b[0m,\n",
       "                        \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m,\n",
       "                    \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                        \u001b[33mindex\u001b[0m=\u001b[1;36m1939\u001b[0m,\n",
       "                        \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mtext\u001b[0m=\u001b[32m\"Deep\u001b[0m\u001b[32m Research by OpenAI is a new capability that enables users to conduct extensive and \u001b[0m\n",
       "\u001b[32mcomplex research tasks quickly and efficiently. Some key features include:\\n\\n1. **Multi-Step Research**: Deep \u001b[0m\n",
       "\u001b[32mResearch allows users to generate outputs through a series of reasoning and data synthesis from numerous online \u001b[0m\n",
       "\u001b[32msources. It can handle intricate queries that would typically require significant human effort.\\n\\n2. \u001b[0m\n",
       "\u001b[32m**Independence and Automation**: Users provide a prompt, and the system independently finds, analyzes, and \u001b[0m\n",
       "\u001b[32msynthesizes the required information, generating comprehensive reports similar to what a research analyst might \u001b[0m\n",
       "\u001b[32mproduce.\\n\\n3. **Web Browsing and Data Analysis**: It utilizes a specialized version of OpenAI's model optimized \u001b[0m\n",
       "\u001b[32mfor web browsing and data analysis, making it capable of interpreting vast amounts of information, including text, \u001b[0m\n",
       "\u001b[32mimages, and PDFs.\\n\\n4. **Documentation and Citations**: Every result is accompanied by detailed documentation and \u001b[0m\n",
       "\u001b[32mcitations, ensuring that users can verify the information and understand the reasoning behind the outputs.\\n\\n5. \u001b[0m\n",
       "\u001b[32m**Targeted Use Cases**: Deep Research is particularly beneficial for professionals in finance, science, policy, and\u001b[0m\n",
       "\u001b[32mengineering, as well as consumers seeking personalized recommendations that require extensive research.\\n\\n6. \u001b[0m\n",
       "\u001b[32m**Performance**: Initial evaluations show that the model powering Deep Research significantly outperforms previous \u001b[0m\n",
       "\u001b[32mmodels in expert-level tasks and public evaluations, achieving higher accuracy.\\n\\n7. **Accessibility and Future \u001b[0m\n",
       "\u001b[32mPlans**: Currently, Deep Research is available to Pro users, with plans to extend access to more user tiers over \u001b[0m\n",
       "\u001b[32mtime, and enhancements will be rolled out to improve the system based on user feedback and usage data.\\n\\nThis \u001b[0m\n",
       "\u001b[32mrepresents a notable advancement towards OpenAI's broader goal of achieving artificial general intelligence \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAGI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mspecifically in the realm of knowledge synthesis and research capabilities.\"\u001b[0m,\n",
       "                \u001b[33mtype\u001b[0m=\u001b[32m'output_text'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "        \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'message'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = openai.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"What is deep research by OpenAI?\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store.id]\n",
    "    }]\n",
    ")\n",
    "rich.print(response.output[1].content[0].text)\n",
    "# rich.print(response)\n",
    "rich.print(response.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb5fe8",
   "metadata": {},
   "source": [
    "Customize the number of results you want to retrieve from the vector stores.\n",
    "\n",
    "\n",
    "You will notice a change in the result only if you also provide `include=[\"file_search_call.results\"]`. This will allow you to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3588d02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Deep research by OpenAI is a new capability launched in ChatGPT that enables the AI to conduct multi-step research \n",
       "on the internet. This feature allows users to offload complex research tasks, synthesizing vast amounts of online \n",
       "information into comprehensive reports akin to those of a research analyst. It achieves this through advanced \n",
       "reasoning and browsing capabilities optimized for tasks requiring extensive information gathering.\n",
       "\n",
       "### Key Features\n",
       "- **Agentic Capability**: Users provide a prompt, and the AI independently finds, analyzes, and synthesizes \n",
       "information from hundreds of online sources.\n",
       "- **Multi-step Tasks**: It can complete complex research tasks that would otherwise take a significant amount of \n",
       "human time.\n",
       "- **Comprehensive Outputs**: Every output is fully documented with citations and summaries, making the information \n",
       "easy to reference.\n",
       "- **Wide Applications**: Particularly useful for intensive knowledge work in sectors like finance, science, policy,\n",
       "and engineering, as well as for personalized shopping research.\n",
       "\n",
       "The development of deep research aligns with OpenAI's broader goals towards creating Artificial General \n",
       "Intelligence <span style=\"font-weight: bold\">(</span>AGI<span style=\"font-weight: bold\">)</span> capable of generating new scientific knowledge, as it synthesizes information to generate \n",
       "valuable insights.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Deep research by OpenAI is a new capability launched in ChatGPT that enables the AI to conduct multi-step research \n",
       "on the internet. This feature allows users to offload complex research tasks, synthesizing vast amounts of online \n",
       "information into comprehensive reports akin to those of a research analyst. It achieves this through advanced \n",
       "reasoning and browsing capabilities optimized for tasks requiring extensive information gathering.\n",
       "\n",
       "### Key Features\n",
       "- **Agentic Capability**: Users provide a prompt, and the AI independently finds, analyzes, and synthesizes \n",
       "information from hundreds of online sources.\n",
       "- **Multi-step Tasks**: It can complete complex research tasks that would otherwise take a significant amount of \n",
       "human time.\n",
       "- **Comprehensive Outputs**: Every output is fully documented with citations and summaries, making the information \n",
       "easy to reference.\n",
       "- **Wide Applications**: Particularly useful for intensive knowledge work in sectors like finance, science, policy,\n",
       "and engineering, as well as for personalized shopping research.\n",
       "\n",
       "The development of deep research aligns with OpenAI's broader goals towards creating Artificial General \n",
       "Intelligence \u001b[1m(\u001b[0mAGI\u001b[1m)\u001b[0m capable of generating new scientific knowledge, as it synthesizes information to generate \n",
       "valuable insights.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Result</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">attributes</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">score</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9820093016280954</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Introducing deep research | OpenAI\\n\\n\\nFebruary 2, 2025 Release\\n\\nIntroducing deep research\\nAn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent that uses reasoning to synthesize large amounts of\\nonline information and complete multi-step research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks\\nfor you. Available to Pro users today, Plus and Team next.\\n\\nTry on ChatGPT\\n\\nListen to article 8:18 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Share\\n\\n21/02/2025, 19:58 Introducing deep research | </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">1/38\\n\\nhttps://openai.com/research/index/release/\\nhttps://chatgpt.com/\\nhttps://openai.com/\\n\\n\\nToday we’re </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">launching deep research in ChatGPT, a new agentic capability that\\nconducts multi-step research on the internet for</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks. It accomplishes in\\ntens of minutes what would take a human many hours.\\n\\nDeep research is OpenAI's</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">next agent that can do work for you independently—you\\ngive it a prompt, and ChatGPT will find, analyze, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthesize hundreds of online\\nsources to create a comprehensive report at the level of a research analyst. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Powered\\nby a version of the upcoming OpenAI o3 model that’s optimized for web browsing and\\ndata analysis, it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leverages reasoning to search, interpret, and analyze massive amounts\\nof text, images, and PDFs on the internet, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pivoting as needed in reaction to information\\nit encounters.\\n\\nThe ability to synthesize knowledge is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prerequisite for creating new knowledge. For\\nthis reason, deep research marks a significant step toward our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">broader goal of\\ndeveloping AGI, which we have long envisioned as capable of producing novel\\nscientific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research.\\n\\nWhy we built deep research\\n\\nDeep research is built for people who do intensive knowledge work in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">areas like\\nfinance, science, policy, and engineering and need thorough, precise, and reliable\\nresearch. It can be</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">equally useful for discerning shoppers looking for hyper-\\npersonalized recommendations on purchases that typically</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">require careful research,\\nlike cars, appliances, and furniture. Every output is fully documented, with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clear\\ncitations and a summary of its thinking, making it easy to reference and verify the\\ninformation. It is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly effective at finding niche, non-intuitive information that\\nwould require browsing numerous websites. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Deep research frees up valuable time by\\nallowing you to offload and expedite complex, time-intensive web research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with just\\none query.\\n\\nDeep research independently discovers, reasons about, and consolidates insights </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from\\nacross the web. To accomplish this, it was trained on real-world tasks requiring\\nbrowser and Python tool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use, using the same reinforcement learning methods behind\\nOpenAI o1, our first reasoning model. While o1 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">demonstrates impressive capabilities in\\n\\n21/02/2025, 19:58 Introducing deep research | </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ 2/38\\n\\nhttps://openai.com/\\n\\n\\ncoding, math, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other technical domains, many real-world challenges demand\\nextensive context and information gathering from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">diverse online sources. Deep\\nresearch builds on these reasoning capabilities to bridge that gap, allowing it to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">take\\non the types of problems people face in work and everyday life.\\n\\nHow to use deep research\\n\\nIn ChatGPT, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">select ‘deep research’ in the message composer and enter your query. Tell\\nChatGPT what you need—whether it’s a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">competitive analysis on streaming platforms\\nor a personalized report on the best commuter bike. You can attach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">files or\\nspreadsheets to add context to your question. Once it starts running, a sidebar\\nappears with a summary </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of the steps taken and sources used.\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Result</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">attributes</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">score</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.946322956540013</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Deep research\\n\\nHelp me find iOS and android adoption rates, % who want to learn\\nanother language, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and change in mobile penetration, over the past 10\\nyears, for top 10 developed and top 10 developing countries by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GDP.\\nLay this info out in a table and separate stats into columns, and include\\nrecommendations on markets to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">target for a new iOS translation app\\nfrom ChatGPT, focusing on markets ChatGPT is currently active in.\\n\\nTop 10 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Developed Economies (by GDP) – Smartphone OS Share,\\n\\nLanguage-Learning Interest, and Mobile Penetration </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Growth\\n\\nCountry iOS\\n\\nMarket\\n\\nShare\\n\\nAndroid\\n\\nMarket\\n\\nShare\\n\\nInterest in New\\n\\nLanguage\\n\\n(% of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">population)\\n\\nMobile\\n\\nPenetration\\n\\nChange\\n\\n(2013→2023)\\n\\n21/02/2025, 19:58 Introducing deep research | </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ 4/38\\n\\nhttps://openai.com/\\n\\n\\nHow it works\\n\\nDeep</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research was trained using end-to-end reinforcement learning on hard browsing\\nand reasoning tasks across a range </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of domains. Through that training, it learned to\\nplan and execute a multi-step trajectory to find the data it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">needs, backtracking and\\nreacting to real-time information where necessary. The model is also able to browse\\nover </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user uploaded files, plot and iterate on graphs using the python tool, embed both\\ngenerated graphs and images from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">websites in its responses, and cite specific\\nsentences or passages from its sources. As a result of this training,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">it reaches new\\nhighs on a number of public evaluations focused on real-world problems.\\n\\nHumanity's Last </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Exam\\n\\nOn Humanity’s Last Exam , a recently released evaluation that tests AI across a broad\\nrange of subjects on</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expert-level questions, the model powering deep research scores\\na new high at 26.6% accuracy. This test consists </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of over 3,000 multiple choice and\\nshort answer questions across more than 100 subjects from linguistics to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocket\\nscience, classics to ecology. Compared to OpenAI o1, the largest gains appeared in\\nchemistry, humanities </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and social sciences, and mathematics. The model powering\\ndeep research showcased a human-like approach by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively seeking out\\nspecialized information when necessary.\\n\\nModel\\nAccuracy\\n\\n(%)\\n\\nGPT-4o 3.3\\n\\nGrok-2 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">3.8\\n\\nClaude 3.5 Sonnet 4.3\\n\\ncomparison. It uses that information to offer detailed market-entry recommendations</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that are\\ninformed and usable.\\n\\n21/02/2025, 19:58 Introducing deep research | </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">5/38\\n\\nhttps://lastexam.ai/\\nhttps://openai.com/\\n\\n\\nModel\\nAccuracy\\n\\n(%)\\n\\nGemini Thinking 6.2\\n\\nOpenAI o1 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">9.1\\n\\nDeepSeek-R1* 9.4\\n\\nOpenAI o3-mini\\n(medium)*\\n\\n10.5\\n\\nOpenAI o3-mini (high)* 13.0\\n\\nOpenAI deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research** 26.6\\n\\n* Model is not multi-modal,\\nevaluated on text-only subset.\\n**with browsing + python </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools\\n\\nGAIA\\n\\nOn GAIA , a public benchmark that evaluates AI on real-world questions, the model\\npowering deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research reaches a new state of the art (SOTA), topping the external\\nleaderboard . Encompassing questions across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">three levels of difficulty, successful\\ncompletion of these tasks requires abilities including reasoning, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multi-modal fluency,\\nweb browsing, and tool-use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">proficiency.\\n\\nGAIA\\n\\nLevel\\n\\n1\\n\\nLevel\\n\\n2\\n\\nLevel\\n\\n3\\nAvg.\\n\\n67.92 67.44 42.31 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">63.64\\n\\nDeep\\nResearch\\n(pass@1)\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mattributes\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m,\n",
       "        \u001b[33mscore\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9820093016280954\u001b[0m,\n",
       "        \u001b[33mtext\u001b[0m=\u001b[32m\"Introducing\u001b[0m\u001b[32m deep research | OpenAI\\n\\n\\nFebruary 2, 2025 Release\\n\\nIntroducing deep research\\nAn \u001b[0m\n",
       "\u001b[32magent that uses reasoning to synthesize large amounts of\\nonline information and complete multi-step research \u001b[0m\n",
       "\u001b[32mtasks\\nfor you. Available to Pro users today, Plus and Team next.\\n\\nTry on ChatGPT\\n\\nListen to article 8:18 \u001b[0m\n",
       "\u001b[32mShare\\n\\n21/02/2025, 19:58 Introducing deep research | \u001b[0m\n",
       "\u001b[32mOpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ \u001b[0m\n",
       "\u001b[32m1/38\\n\\nhttps://openai.com/research/index/release/\\nhttps://chatgpt.com/\\nhttps://openai.com/\\n\\n\\nToday we’re \u001b[0m\n",
       "\u001b[32mlaunching deep research in ChatGPT, a new agentic capability that\\nconducts multi-step research on the internet for\u001b[0m\n",
       "\u001b[32mcomplex tasks. It accomplishes in\\ntens of minutes what would take a human many hours.\\n\\nDeep research is OpenAI's\u001b[0m\n",
       "\u001b[32mnext agent that can do work for you independently—you\\ngive it a prompt, and ChatGPT will find, analyze, and \u001b[0m\n",
       "\u001b[32msynthesize hundreds of online\\nsources to create a comprehensive report at the level of a research analyst. \u001b[0m\n",
       "\u001b[32mPowered\\nby a version of the upcoming OpenAI o3 model that’s optimized for web browsing and\\ndata analysis, it \u001b[0m\n",
       "\u001b[32mleverages reasoning to search, interpret, and analyze massive amounts\\nof text, images, and PDFs on the internet, \u001b[0m\n",
       "\u001b[32mpivoting as needed in reaction to information\\nit encounters.\\n\\nThe ability to synthesize knowledge is a \u001b[0m\n",
       "\u001b[32mprerequisite for creating new knowledge. For\\nthis reason, deep research marks a significant step toward our \u001b[0m\n",
       "\u001b[32mbroader goal of\\ndeveloping AGI, which we have long envisioned as capable of producing novel\\nscientific \u001b[0m\n",
       "\u001b[32mresearch.\\n\\nWhy we built deep research\\n\\nDeep research is built for people who do intensive knowledge work in \u001b[0m\n",
       "\u001b[32mareas like\\nfinance, science, policy, and engineering and need thorough, precise, and reliable\\nresearch. It can be\u001b[0m\n",
       "\u001b[32mequally useful for discerning shoppers looking for hyper-\\npersonalized recommendations on purchases that typically\u001b[0m\n",
       "\u001b[32mrequire careful research,\\nlike cars, appliances, and furniture. Every output is fully documented, with \u001b[0m\n",
       "\u001b[32mclear\\ncitations and a summary of its thinking, making it easy to reference and verify the\\ninformation. It is \u001b[0m\n",
       "\u001b[32mparticularly effective at finding niche, non-intuitive information that\\nwould require browsing numerous websites. \u001b[0m\n",
       "\u001b[32mDeep research frees up valuable time by\\nallowing you to offload and expedite complex, time-intensive web research \u001b[0m\n",
       "\u001b[32mwith just\\none query.\\n\\nDeep research independently discovers, reasons about, and consolidates insights \u001b[0m\n",
       "\u001b[32mfrom\\nacross the web. To accomplish this, it was trained on real-world tasks requiring\\nbrowser and Python tool \u001b[0m\n",
       "\u001b[32muse, using the same reinforcement learning methods behind\\nOpenAI o1, our first reasoning model. While o1 \u001b[0m\n",
       "\u001b[32mdemonstrates impressive capabilities in\\n\\n21/02/2025, 19:58 Introducing deep research | \u001b[0m\n",
       "\u001b[32mOpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ 2/38\\n\\nhttps://openai.com/\\n\\n\\ncoding, math, and \u001b[0m\n",
       "\u001b[32mother technical domains, many real-world challenges demand\\nextensive context and information gathering from \u001b[0m\n",
       "\u001b[32mdiverse online sources. Deep\\nresearch builds on these reasoning capabilities to bridge that gap, allowing it to \u001b[0m\n",
       "\u001b[32mtake\\non the types of problems people face in work and everyday life.\\n\\nHow to use deep research\\n\\nIn ChatGPT, \u001b[0m\n",
       "\u001b[32mselect ‘deep research’ in the message composer and enter your query. Tell\\nChatGPT what you need—whether it’s a \u001b[0m\n",
       "\u001b[32mcompetitive analysis on streaming platforms\\nor a personalized report on the best commuter bike. You can attach \u001b[0m\n",
       "\u001b[32mfiles or\\nspreadsheets to add context to your question. Once it starts running, a sidebar\\nappears with a summary \u001b[0m\n",
       "\u001b[32mof the steps taken and sources used.\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mattributes\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "        \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m,\n",
       "        \u001b[33mscore\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.946322956540013\u001b[0m,\n",
       "        \u001b[33mtext\u001b[0m=\u001b[32m\"Deep\u001b[0m\u001b[32m research\\n\\nHelp me find iOS and android adoption rates, % who want to learn\\nanother language, \u001b[0m\n",
       "\u001b[32mand change in mobile penetration, over the past 10\\nyears, for top 10 developed and top 10 developing countries by \u001b[0m\n",
       "\u001b[32mGDP.\\nLay this info out in a table and separate stats into columns, and include\\nrecommendations on markets to \u001b[0m\n",
       "\u001b[32mtarget for a new iOS translation app\\nfrom ChatGPT, focusing on markets ChatGPT is currently active in.\\n\\nTop 10 \u001b[0m\n",
       "\u001b[32mDeveloped Economies \u001b[0m\u001b[32m(\u001b[0m\u001b[32mby GDP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m – Smartphone OS Share,\\n\\nLanguage-Learning Interest, and Mobile Penetration \u001b[0m\n",
       "\u001b[32mGrowth\\n\\nCountry iOS\\n\\nMarket\\n\\nShare\\n\\nAndroid\\n\\nMarket\\n\\nShare\\n\\nInterest in New\\n\\nLanguage\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m% of \u001b[0m\n",
       "\u001b[32mpopulation\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nMobile\\n\\nPenetration\\n\\nChange\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2013→2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n21/02/2025, 19:58 Introducing deep research | \u001b[0m\n",
       "\u001b[32mOpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ 4/38\\n\\nhttps://openai.com/\\n\\n\\nHow it works\\n\\nDeep\u001b[0m\n",
       "\u001b[32mresearch was trained using end-to-end reinforcement learning on hard browsing\\nand reasoning tasks across a range \u001b[0m\n",
       "\u001b[32mof domains. Through that training, it learned to\\nplan and execute a multi-step trajectory to find the data it \u001b[0m\n",
       "\u001b[32mneeds, backtracking and\\nreacting to real-time information where necessary. The model is also able to browse\\nover \u001b[0m\n",
       "\u001b[32muser uploaded files, plot and iterate on graphs using the python tool, embed both\\ngenerated graphs and images from\u001b[0m\n",
       "\u001b[32mwebsites in its responses, and cite specific\\nsentences or passages from its sources. As a result of this training,\u001b[0m\n",
       "\u001b[32mit reaches new\\nhighs on a number of public evaluations focused on real-world problems.\\n\\nHumanity's Last \u001b[0m\n",
       "\u001b[32mExam\\n\\nOn Humanity’s Last Exam , a recently released evaluation that tests AI across a broad\\nrange of subjects on\u001b[0m\n",
       "\u001b[32mexpert-level questions, the model powering deep research scores\\na new high at 26.6% accuracy. This test consists \u001b[0m\n",
       "\u001b[32mof over 3,000 multiple choice and\\nshort answer questions across more than 100 subjects from linguistics to \u001b[0m\n",
       "\u001b[32mrocket\\nscience, classics to ecology. Compared to OpenAI o1, the largest gains appeared in\\nchemistry, humanities \u001b[0m\n",
       "\u001b[32mand social sciences, and mathematics. The model powering\\ndeep research showcased a human-like approach by \u001b[0m\n",
       "\u001b[32meffectively seeking out\\nspecialized information when necessary.\\n\\nModel\\nAccuracy\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nGPT-4o 3.3\\n\\nGrok-2 \u001b[0m\n",
       "\u001b[32m3.8\\n\\nClaude 3.5 Sonnet 4.3\\n\\ncomparison. It uses that information to offer detailed market-entry recommendations\u001b[0m\n",
       "\u001b[32mthat are\\ninformed and usable.\\n\\n21/02/2025, 19:58 Introducing deep research | \u001b[0m\n",
       "\u001b[32mOpenAI\\n\\nhttps://openai.com/index/introducing-deep-research/ \u001b[0m\n",
       "\u001b[32m5/38\\n\\nhttps://lastexam.ai/\\nhttps://openai.com/\\n\\n\\nModel\\nAccuracy\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nGemini Thinking 6.2\\n\\nOpenAI o1 \u001b[0m\n",
       "\u001b[32m9.1\\n\\nDeepSeek-R1* 9.4\\n\\nOpenAI o3-mini\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmedium\u001b[0m\u001b[32m)\u001b[0m\u001b[32m*\\n\\n10.5\\n\\nOpenAI o3-mini \u001b[0m\u001b[32m(\u001b[0m\u001b[32mhigh\u001b[0m\u001b[32m)\u001b[0m\u001b[32m* 13.0\\n\\nOpenAI deep \u001b[0m\n",
       "\u001b[32mresearch** 26.6\\n\\n* Model is not multi-modal,\\nevaluated on text-only subset.\\n**with browsing + python \u001b[0m\n",
       "\u001b[32mtools\\n\\nGAIA\\n\\nOn GAIA , a public benchmark that evaluates AI on real-world questions, the model\\npowering deep \u001b[0m\n",
       "\u001b[32mresearch reaches a new state of the art \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSOTA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, topping the external\\nleaderboard . Encompassing questions across \u001b[0m\n",
       "\u001b[32mthree levels of difficulty, successful\\ncompletion of these tasks requires abilities including reasoning, \u001b[0m\n",
       "\u001b[32mmulti-modal fluency,\\nweb browsing, and tool-use \u001b[0m\n",
       "\u001b[32mproficiency.\\n\\nGAIA\\n\\nLevel\\n\\n1\\n\\nLevel\\n\\n2\\n\\nLevel\\n\\n3\\nAvg.\\n\\n67.92 67.44 42.31 \u001b[0m\n",
       "\u001b[32m63.64\\n\\nDeep\\nResearch\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpass@1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'msg_67e38bf681bc819290cbe60da20ab788069a0f3d2e156a04'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputText</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnnotationFileCitation</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">file_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-4GoREtVZ14bPdCKHXsva8k'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1279</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file_citation'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deep_research_blog.pdf'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Deep research by OpenAI is a new capability launched in ChatGPT that enables the AI to conduct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multi-step research on the internet. This feature allows users to offload complex research tasks, synthesizing vast</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">amounts of online information into comprehensive reports akin to those of a research analyst. It achieves this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">through advanced reasoning and browsing capabilities optimized for tasks requiring extensive information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gathering.\\n\\n### Key Features\\n- **Agentic Capability**: Users provide a prompt, and the AI independently finds, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">analyzes, and synthesizes information from hundreds of online sources.\\n- **Multi-step Tasks**: It can complete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex research tasks that would otherwise take a significant amount of human time.\\n- **Comprehensive Outputs**: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Every output is fully documented with citations and summaries, making the information easy to reference.\\n- **Wide </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Applications**: Particularly useful for intensive knowledge work in sectors like finance, science, policy, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engineering, as well as for personalized shopping research.\\n\\nThe development of deep research aligns with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OpenAI's broader goals towards creating Artificial General Intelligence (AGI) capable of generating new scientific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge, as it synthesizes information to generate valuable insights.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'output_text'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mResponseOutputMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'msg_67e38bf681bc819290cbe60da20ab788069a0f3d2e156a04'\u001b[0m,\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mResponseOutputText\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAnnotationFileCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mfile_id\u001b[0m=\u001b[32m'file-4GoREtVZ14bPdCKHXsva8k'\u001b[0m,\n",
       "                    \u001b[33mindex\u001b[0m=\u001b[1;36m1279\u001b[0m,\n",
       "                    \u001b[33mtype\u001b[0m=\u001b[32m'file_citation'\u001b[0m,\n",
       "                    \u001b[33mfilename\u001b[0m=\u001b[32m'deep_research_blog.pdf'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtext\u001b[0m=\u001b[32m\"Deep\u001b[0m\u001b[32m research by OpenAI is a new capability launched in ChatGPT that enables the AI to conduct \u001b[0m\n",
       "\u001b[32mmulti-step research on the internet. This feature allows users to offload complex research tasks, synthesizing vast\u001b[0m\n",
       "\u001b[32mamounts of online information into comprehensive reports akin to those of a research analyst. It achieves this \u001b[0m\n",
       "\u001b[32mthrough advanced reasoning and browsing capabilities optimized for tasks requiring extensive information \u001b[0m\n",
       "\u001b[32mgathering.\\n\\n### Key Features\\n- **Agentic Capability**: Users provide a prompt, and the AI independently finds, \u001b[0m\n",
       "\u001b[32manalyzes, and synthesizes information from hundreds of online sources.\\n- **Multi-step Tasks**: It can complete \u001b[0m\n",
       "\u001b[32mcomplex research tasks that would otherwise take a significant amount of human time.\\n- **Comprehensive Outputs**: \u001b[0m\n",
       "\u001b[32mEvery output is fully documented with citations and summaries, making the information easy to reference.\\n- **Wide \u001b[0m\n",
       "\u001b[32mApplications**: Particularly useful for intensive knowledge work in sectors like finance, science, policy, and \u001b[0m\n",
       "\u001b[32mengineering, as well as for personalized shopping research.\\n\\nThe development of deep research aligns with \u001b[0m\n",
       "\u001b[32mOpenAI's broader goals towards creating Artificial General Intelligence \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAGI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m capable of generating new scientific \u001b[0m\n",
       "\u001b[32mknowledge, as it synthesizes information to generate valuable insights.\"\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'output_text'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "    \u001b[33mtype\u001b[0m=\u001b[32m'message'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = openai.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"What is deep research by OpenAI?\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store.id],\n",
    "        \"max_num_results\": 2  \n",
    "    }],\n",
    "    include=[\"file_search_call.results\"]  # This will include actual portion of text content from the file\n",
    ")\n",
    "rich.print(response.output[1].content[0].text)\n",
    "# rich.print(response)\n",
    "rich.print(response.output[0].results)\n",
    "rich.print(response.output[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
